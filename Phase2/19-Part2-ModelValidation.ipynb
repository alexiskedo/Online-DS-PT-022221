{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple Linear Regression, Part 2: \n",
    "\n",
    "## Model Validation\n",
    "\n",
    "Today we'll focus on how to validate our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up Our Data Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit data from https://www.kaggle.com/avikpaul4u/credit-card-balance\n",
    "\n",
    "Target: `Balance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "df = pd.read_csv('data/Credit.csv', \n",
    "                 usecols=['Income', 'Limit', 'Rating', 'Age', 'Balance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.891</td>\n",
       "      <td>3606</td>\n",
       "      <td>283</td>\n",
       "      <td>34</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.025</td>\n",
       "      <td>6645</td>\n",
       "      <td>483</td>\n",
       "      <td>82</td>\n",
       "      <td>903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.593</td>\n",
       "      <td>7075</td>\n",
       "      <td>514</td>\n",
       "      <td>71</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>148.924</td>\n",
       "      <td>9504</td>\n",
       "      <td>681</td>\n",
       "      <td>36</td>\n",
       "      <td>964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55.882</td>\n",
       "      <td>4897</td>\n",
       "      <td>357</td>\n",
       "      <td>68</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Income  Limit  Rating  Age  Balance\n",
       "0   14.891   3606     283   34      333\n",
       "1  106.025   6645     483   82      903\n",
       "2  104.593   7075     514   71      580\n",
       "3  148.924   9504     681   36      964\n",
       "4   55.882   4897     357   68      331"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Income</th>\n",
       "      <th>Limit</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Age</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>400.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>45.218885</td>\n",
       "      <td>4735.600000</td>\n",
       "      <td>354.940000</td>\n",
       "      <td>55.667500</td>\n",
       "      <td>520.015000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.244273</td>\n",
       "      <td>2308.198848</td>\n",
       "      <td>154.724143</td>\n",
       "      <td>17.249807</td>\n",
       "      <td>459.758877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.354000</td>\n",
       "      <td>855.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>21.007250</td>\n",
       "      <td>3088.000000</td>\n",
       "      <td>247.250000</td>\n",
       "      <td>41.750000</td>\n",
       "      <td>68.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>33.115500</td>\n",
       "      <td>4622.500000</td>\n",
       "      <td>344.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>459.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>57.470750</td>\n",
       "      <td>5872.750000</td>\n",
       "      <td>437.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>863.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>186.634000</td>\n",
       "      <td>13913.000000</td>\n",
       "      <td>982.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Income         Limit      Rating         Age      Balance\n",
       "count  400.000000    400.000000  400.000000  400.000000   400.000000\n",
       "mean    45.218885   4735.600000  354.940000   55.667500   520.015000\n",
       "std     35.244273   2308.198848  154.724143   17.249807   459.758877\n",
       "min     10.354000    855.000000   93.000000   23.000000     0.000000\n",
       "25%     21.007250   3088.000000  247.250000   41.750000    68.750000\n",
       "50%     33.115500   4622.500000  344.000000   56.000000   459.500000\n",
       "75%     57.470750   5872.750000  437.250000   70.000000   863.000000\n",
       "max    186.634000  13913.000000  982.000000   98.000000  1999.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1a6fe1782b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.pairplot(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Practice\n",
    "\n",
    "Last time, we left off after identifying some issues in our initial multiple linear regression model. Let's build that model back - now, with sklearn! - and then discuss one change we can implement and see if it improves our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X and y\n",
    "\n",
    "used_cols = [c for c in df.columns if c not in ['Balance']]\n",
    "\n",
    "X = df[used_cols]\n",
    "y = df['Balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's be sure to scale our X variables\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit our model!\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8772\n",
      "MAE: 120.3084\n",
      "RMSE: 160.8886\n"
     ]
    }
   ],
   "source": [
    "# Grab our predictions and evaluate\n",
    "y_preds = lr.predict(X_scaled)\n",
    "\n",
    "print(f\"R2 Score: {r2_score(y, y_preds):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y, y_preds):.4f}\")\n",
    "print(f\"RMSE: {mean_squared_error(y, y_preds, squared=False):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE is in the same units as our Y \n",
    "# MAE is the average of the difference \n",
    "# between the predicted and measured values \n",
    "\n",
    "# RMSE = differences are over-emphasized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-267.96762972,  188.64828933,  422.08825003,  -14.74939325])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_\n",
    "# A way to get the coefficients \n",
    "# Aligns with each of the four used columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520.0150000000001"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.intercept_\n",
    "# Y-intercept is stored separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 27., 111.,  95.,  76.,  28.,  23.,  11.,  11.,  12.,   6.]),\n",
       " array([-249.61848088, -170.00497143,  -90.39146197,  -10.77795252,\n",
       "          68.83555694,  148.44906639,  228.06257584,  307.6760853 ,\n",
       "         387.28959475,  466.90310421,  546.51661366]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize our residuals\n",
    "residuals = y - y_preds \n",
    "\n",
    "plt.hist(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What issues are there with this model?\n",
    "\n",
    "- Residuals aren't normaly distributed; one one side we're off by more than the other\n",
    "- Multicollinearity between our x variables \n",
    "\n",
    "\n",
    "#### Now, make a change!\n",
    "\n",
    "- just use a few x variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_cols = ['Rating', 'Income']\n",
    "\n",
    "X = df[used_cols]\n",
    "y = df['Balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale them again so that the two regressions can be compared \n",
    "scaler2 = StandardScaler()\n",
    "X_scaled2 = scaler2.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2 = LinearRegression()\n",
    "\n",
    "lr2.fit(X_scaled2, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.8751\n",
      "MAE: 120.7972\n",
      "RMSE: 162.2694\n"
     ]
    }
   ],
   "source": [
    "y_preds2 = lr2.predict(X_scaled2)\n",
    "\n",
    "print(f\"R2 Score: {r2_score(y, y_preds2):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y, y_preds2):.4f}\")\n",
    "print(f\"RMSE: {mean_squared_error(y, y_preds2, squared=False):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-267.96762972,  188.64828933,  422.08825003,  -14.74939325])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520.015"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr2.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation - AKA How to Build Generalizable Models\n",
    "\n",
    "![validation gif from giphy](https://media.giphy.com/media/242wLqQerWkxd6GgHB/giphy.gif)\n",
    "\n",
    "Our premise: Let's say you have a dataframe, with some number of rows of data, and that's all you have available to you. The hope is that you can train a model on this data that can then be used to make predictions about new data that comes in. You want your model to _generalize_ well and work on this incoming data - not too complex from learning all the details/noise from the data, but also not so simple that the model is useless. How do we do that?\n",
    "\n",
    "First, let's go into detail about this trade-off between simplicity and complexity:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Bias-Variance Trade Off\n",
    "\n",
    "<img alt=\"original image from https://rmartinshort.jimdofree.com/2019/02/17/overfitting-bias-variance-and-leaning-curves/\" src=\"images/underfit-goodfit-overfit.png\" width=750, height=350>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember - by modeling, we're assuming that there is some relationship between our X variables (the features in our dataset) and our y variable (the target). Thus, there is some underlying '_true_' function that captures the relationship between X and y, which we are trying to find by modeling. Of course, the actual relationship may be quite complex and not wholly represented in our data - our approximation, aka the model we create, is likely only a simplified estimator of whatever our '_true_' function actually would look like.\n",
    "\n",
    "**Bias**: Error introduced by approximating a real-life problem (which may be extremely complicated) by a much simpler model (because the model is too simple to capture the underlying pattern)\n",
    "\n",
    "**Variance**: Amount by which our model would change if we estimated it using a different training dataset (because the model is over-learning from the training data)\n",
    "\n",
    "**Representation:**\n",
    "\n",
    "<img alt=\"from https://hsto.org/files/281/108/1e9/2811081e9eda44d08f350be5a9deb564.png\" src=\"images/bias-variance.png/\" width=350, height=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How To Minimize Bias and Variance\n",
    "\n",
    "Good news! There are tried and true methods to reducing both bias and variance in our modeling process. Testing different models, trying models on different slices of data, transforming or engineering features - all of these things have a role to play in creating better, more robust models.\n",
    "\n",
    "In particular, we've learned so far that we can evaluate the performance of our models, using a scoring metric, which will help us catch if a model is underfit - if it's performing quite poorly, it probably isn't capturing the relationship in our data! \n",
    "\n",
    "But what about overfitting?\n",
    "\n",
    "<img alt=\"I Love Lucy shrug gif from Giphy\" src=\"https://media.giphy.com/media/JRhS6WoswF8FxE0g2R/giphy.gif\" width=350, height=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Split\n",
    "\n",
    "The idea: don't train your model on ALL of your data, but keep some of it in reserve to test on, in order to simulate how it will work on new/incoming data.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "<img alt=\"original image from https://www.dataquest.io/wp-content/uploads/kaggle_train_test_split.svg plus some added commentary\" src=\"images/traintestsplit_80-20.png\" width=850, height=150>  \n",
    "\n",
    "Note - here, it looks like we're just taking the tail end of the dataset and setting it aside. In practice (most of the time), the split will randomly choose which rows are in the train vs. test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does this fight against overfitting? By witholding data from the training process, we are testing whether the model actually _generalizes_ well. If it does poorly on the test set, it's a good sign that our model learned too much noise from the train set and is overfit! \n",
    "\n",
    "![arrested development gif, found by Andy](https://heavy.com/wp-content/uploads/2013/05/tumblr_mjm9fqhrle1rvnnvyo6_250.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Practice:\n",
    "\n",
    "Documentation: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283</td>\n",
       "      <td>14.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>483</td>\n",
       "      <td>106.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514</td>\n",
       "      <td>104.593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>681</td>\n",
       "      <td>148.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>357</td>\n",
       "      <td>55.882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating   Income\n",
       "0     283   14.891\n",
       "1     483  106.025\n",
       "2     514  104.593\n",
       "3     681  148.924\n",
       "4     357   55.882"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    333\n",
       "1    903\n",
       "2    580\n",
       "3    964\n",
       "4    331\n",
       "Name: Balance, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split here!\n",
    "# Set test_size = .33\n",
    "# Set random_state = 42\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did that do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(268, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train + X_test) == len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>215</td>\n",
       "      <td>41.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>292</td>\n",
       "      <td>22.379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>137</td>\n",
       "      <td>23.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>181</td>\n",
       "      <td>30.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>547</td>\n",
       "      <td>69.943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rating  Income\n",
       "258     215  41.400\n",
       "177     292  22.379\n",
       "119     137  23.012\n",
       "194     181  30.406\n",
       "229     547  69.943"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put our train/test split into practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a new scaler to scale our data\n",
    "# Let's use Standard Scaler here\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit our scaler - ON THE TRAINING DATA!!\n",
    "# Then transform both train and test \n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Same as:\n",
    "# sclaer.fit(X_train)\n",
    "# X_train_scaled = scaler.transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick aside: why is it so important to fit the scaler on the train set instead of the full set of X variables? Let's discuss what exactly these scalers are doing under the hood!\n",
    "\n",
    "- \n",
    "\n",
    "\n",
    "**Rule of thumb:** if something is impacted by other rows in the dataset, it should _**only**_ learn from the training set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an sklearn linear model\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit your model - ON THE TRAINING DATA!!\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab predictions for train and test set\n",
    "y_pred_train  = model.predict(X_train_scaled)\n",
    "y_pred_test = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R2 Score: 0.8810118091252546\n",
      "Test R2 Score: 0.857746253201795\n"
     ]
    }
   ],
   "source": [
    "# How'd we do?\n",
    "\n",
    "print(f\"Train R2 Score: {r2_score(y_train, y_pred_train)}\")\n",
    "print(f\"Test R2 Score: {r2_score(y_test, y_pred_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate!\n",
    "\n",
    "- This is an indication of overfitting! We do better on our train data than ur test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single variable example\n",
    "\n",
    "X_single = df['Rating']\n",
    "y = df['Balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_single, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6656804809053132"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_s_train = scaler.fit_transform(X_train.values.reshape(-1, 1))\n",
    "X_s_test = scaler.transform(X_test.values.reshape(-1, 1))\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_s_train, y_train)\n",
    "lr.score(X_s_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But Wait... There's More!\n",
    "\n",
    "Let's change something and see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed: 0\n",
      "Train R2 Score: 0.8794274393370852\n",
      "Test R2 Score: 0.8638964852587732\n",
      "-----\n",
      "Random Seed: 1\n",
      "Train R2 Score: 0.8723139011791685\n",
      "Test R2 Score: 0.8791035414499949\n",
      "-----\n",
      "Random Seed: 2\n",
      "Train R2 Score: 0.8699112312293716\n",
      "Test R2 Score: 0.8832396098019993\n",
      "-----\n",
      "Random Seed: 3\n",
      "Train R2 Score: 0.8950039553815334\n",
      "Test R2 Score: 0.8353584960458899\n",
      "-----\n",
      "Random Seed: 4\n",
      "Train R2 Score: 0.8718383926546732\n",
      "Test R2 Score: 0.8806890704120296\n",
      "-----\n",
      "Random Seed: 5\n",
      "Train R2 Score: 0.8878718023897032\n",
      "Test R2 Score: 0.8456963219083157\n",
      "-----\n",
      "Random Seed: 6\n",
      "Train R2 Score: 0.8598046057830887\n",
      "Test R2 Score: 0.9027024871969868\n",
      "-----\n",
      "Random Seed: 7\n",
      "Train R2 Score: 0.8840698721013535\n",
      "Test R2 Score: 0.8547020851246395\n",
      "-----\n",
      "Random Seed: 8\n",
      "Train R2 Score: 0.8714547866856557\n",
      "Test R2 Score: 0.8789529885089163\n",
      "-----\n",
      "Random Seed: 9\n",
      "Train R2 Score: 0.873452698312308\n",
      "Test R2 Score: 0.8777877303508429\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "for n in range(10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=0.33, \n",
    "                                                        random_state=n) # <--\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    y_pred_train = lr.predict(X_train_scaled)\n",
    "    y_pred_test = lr.predict(X_test_scaled)\n",
    "    \n",
    "    print(f\"Random Seed: {n}\")\n",
    "    print(f\"Train R2 Score: {r2_score(y_train, y_pred_train)}\")\n",
    "    print(f\"Test R2 Score: {r2_score(y_test, y_pred_test)}\")\n",
    "    print(\"-----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're doing much better on the test score than the train score in some cases, it might be a sign of underfitting. Vice versa = a sign of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here? All we're doing is changing our `random_seed` - why is that having such an impact on our model's scores? Some models appear overfit, some don't - and for some, the test score is **better** than our train score!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation\n",
    "\n",
    "Sometimes, random chance means your training data isn't representative, or includes wacky data like all of our outliers. So, why do just one train-test split when you can do `k` number of them!\n",
    "\n",
    "![cross validation image from kaggle: https://www.kaggle.com/alexisbcook/cross-validation](images/cross-validation.png)\n",
    "\n",
    "The good news is, we'll never actually have to do this by hand - `sklearn` will handle it for us!\n",
    "\n",
    "Documentation: https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K- fold cross variation does k number of train-test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale our data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Note - in practice, better to scale within the cross validate...\n",
    "# But we're saving how to do that with pipelines til later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a fresh linear regression model\n",
    "lr = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's use cross_val_score\n",
    "# Set cv = 5\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(lr, X_scaled, y, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85775875, 0.85167677, 0.88866637, 0.87336143, 0.88521897])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the test scores across our folds\n",
    "scores\n",
    "# Scores are by default r-squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: 0.871 +/- 0.015\n"
     ]
    }
   ],
   "source": [
    "# Print it nicely\n",
    "print(f\"Scores: {scores.mean():.3f} +/- {scores.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why show the standard deviation of scores here? I want some measure of the variance among my scores, so I can tell how different my scores were based on different breakdowns of the training data.\n",
    "\n",
    "If I made a change to my model and the average of my cross-validated scores stayed about the same, but the variance among those scores decreased, that's a better, more generalizable model than before!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Resources:\n",
    "\n",
    "- [Great bias/variance infographic](https://elitedatascience.com/bias-variance-tradeoff) from Elite Data Science\n",
    "- Taking a more statistical approach? [Probabilistic Model Selection with AIC, BIC, and MDL](https://machinelearningmastery.com/probabilistic-model-selection-measures/) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
